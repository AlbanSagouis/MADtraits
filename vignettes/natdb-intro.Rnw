% \VignetteIndexEntry{natdb-intro}
%\VignettePackage{natdb}
%\VignetteEngine{knitr::knitr}
\documentclass[12pt]{article}
\usepackage{amssymb,amsmath}
\usepackage{geometry}
\geometry{letterpaper}
\usepackage{graphicx}
\usepackage{url}
\usepackage{natbib}
\usepackage{color} \definecolor{dark-gray}{gray}{0.3}
\usepackage[colorlinks=true,urlcolor=dark-gray,breaklinks,citecolor=black,linkcolor=black]{hyperref}
\bibliographystyle{besjournals}
\title{An introduction to \emph{natdb}}
\author{William D. Pearse, Maxwell J.Farrell, Konrad C. Hafen, Mallory
    A. Hagadorn, Spencer B. Hudson, Sylvia P. Kinosian, Ryan McCleary,
    Anne E. McManis, Alexandre Rego, \& Kathryn M Welglarz}
\date{\today}
\newcommand{\R}{\texttt{R}\xspace}
\newcommand{\natdb}{\texttt{NATDB}\xspace}

\begin{document}

\maketitle
\tableofcontents
<<include=FALSE>>=
library(natdb)
options(width=40)
@ 
\section{Preamble}
Currently, installing \natdb has two steps: run
\texttt{devtools::install_github("ropensci/suppdata")} and then
\texttt{devtools::install_github("willpearse/natdb")}. Once the \natdb
manuscript is accepted somewhere, a new version of \texttt{suppdata}
and a version of \texttt{natdb} will be uploaded to CRAN, and you will
be able to install by simply running
\texttt{install.packages("natdb")}.

You can get a listing of the functions in the package by typing
\texttt{library(help=natdb)}. If you find any bugs, or have any
feature requests for the package, please use
\href{http://github.com/willpearse/natdb/issues}{the online
  tracker}. Indeed, please contribute to the package using at its
\href{http://github.com/natdb/natdb}{GitHub site}---help is always
welcome!

While \emph{natdb} contains much novel code, it relies heavily on the
\emph{R} ecosystem. In the development of \emph{natdb} we wrote a
great deal of code to help with \emph{suppdata} as well.

\section{Using \natdb}
\natdb is Not A DataBase. Instead, \natdb is a set of code that will
download and collate data to which you already have access, and build
it into a database for you. The distinction is important: it means
that we are not, through \natdb, distributing other people's data, and
so you must cite the original data authors when using the data
(indeed, we would rather you did so at the expense of citing \natdb,
if you are forced to choose).

While that might sound like a lot, getting the data is actually pretty
simple.

<<>>=
library(natdb)                                # 1
data <- natdb(cache="~/natdb/cache")          # 2
clean.data <- clean.natdb(data)               # 3
clean.data
@

The first line loads the \natdb library into your \R session. The
second line does the work of downloading all the data (currently over
110 datasets!) and sorting them into a single \R object for you to
work with. There's something \emph{very important} to note about that
second line: the use of the \texttt{cache}. By specifying an existing
folder for \natdb to use as a cache, \natdb downloads all the datasets
to that folder for you. You don't have to use the same location that I
use (\texttt{~/Code/natdb/cache}), but by using a location of some
sort you ensure that you only have to download all the data once. You
want to do this, because it can take a very long time to download
allthe data. The third line performs a bit of `cleaning' on the
data---neatening up variable and species names that are obviously
intended to be the same thing but are called slightly different things
in different datasets. \natdb doesn't do this by default so that you
can, if you want, check to see whether the decisions we make are the
same that you might make (and, if it's your own data you're
downloading, so that you can disagree with us!). However, you will
almost certainly find that you want to use the `cleaned' version of
\natdb. If you disagree with some of our decisions, let us know by
following the instructions in the section ``\emph{Contributing data
  and/or code to \natdb}''.

<<>>=
str(clean.data)
@ 

Internally, \natdb stores your data in two \texttt{data.frame}s: one
devoted to the numerical (continuous) data, and the other to the
categorical (discrete) data. You can see those two kinds of data in
the code snippet above, which shows the \texttt{str}ucture of the
data. \natdb stores information about the species, variable, value (of
the trait), and meta-data associated with that data (in the format
\texttt{type of metadata:value}) in a reasonably straightforward way
that you can just look at for yourself.

<<>>=
subset.data <- clean.data[c("quercus_robur","quercus_ilex","quercus_rubra"),c("specific_leaf_area","seed_mass")]
data.frame <- as.data.frame(subset.data)
head(data.frame)
@ 

That format of data isn't the most useful for working with the data,
so \natdb comes with a convenience function to summarise your data
into a \texttt{data.frame} where each row represents a single species,
and each column a single trait value. If you look at the help file for
\texttt{as.data.frame.natdb} you'll see that it's possible to
summarise your data using whatever kind of summary function you wish
(it doesn't have to be the mean of the numeric data and the modal
value for the categorical data). If you're familiar with functions
like \texttt{reshape}, you have probably guessed that you can work
with the data as stored in the \texttt{natdb} object itself as
well---this is totally fine. This is, in fact, the reason we haven't
written a convenience function to work with the meta-data stored
within \texttt{natdb}: we can't think of a good way to summraise
meta-data collected over lots of different datasets into a single,
useful value that all users would like, and even if we could it would
only work for the default values of \texttt{as.data.frame.natdb}. If
you have any better ideas, please let us know!

Notice that, in the snippet above, we subset our data, using the
\texttt{[species\_names , trait\_names]} syntax, down to some species
and traits that we were interested in. This is important, because
there are over three-and-a-half million datapoints within \natdb. If
you turn the entire dataset into a \texttt{data.frame}, it'll be too
big for you to do very much that's useful with it. You can use the
\texttt{species} and \texttt{traits} functions to figure out what's in
\natdb if you want.

<<>>=
clean.data <- convert.natdb.units(subset.data)
clean.data <- lookup.natdb.names(subset.data)
@ 

If you've worked with large datasets before, you've probably noticed
that unit and species names can vary across them. The convenience
functions \texttt{convert.natdb.units} and \texttt{lookup.natdb.names}
help with `cleaning up' units and taxonomic names within \natdb. Give
these a try---in particular, you will likely not want to work with
data whose units you haven't made the same throughout as otherwise
you'll be multiplying apples by oranges!

\section{Examples of what you can do with \natdb}
\subsection*{Calculating phylogenetic signal}
First of all, let's download a phylogeny of all mammals (using
\texttt{suppdata}):

<<>>=
library(suppdata)
tree <- read.nexus(suppdata("10.1111/j.1461-0248.2009.01307.x", 1))[[1]]
@ 

...pretty cool, huh? Anyway, now we've got that, let's grab data on
body mass for all these species using \natdb (there's more available -
take a look!):

<<>>=
# This bit you've seen before
library(natdb)
data <- natdb(cache="~/Code/natdb/cache")
clean.data <- clean.natdb(data)

# Make sure the species names match, and then grab only the data we want
tree$tip.label <- tolower(tree$tip.label)
mammal.data <- clean.data[tree$tip.label, "body_mass"]
mammal.data <- as.data.frame(mammal.data)
@

And now for ``The Science Bit'': let's calculate phylogenetic signal
using \texttt{phytools}:

<<>>=
library(phytools)
phylosig(tree, mammal.data$body.mass)
@ 

\subsection*{Calculating ecological indices}
Great, we've got a phylogeny and some body mass data for mammals. Now
let's look at the distribution of body mass in some mammal
assemblages---this is a common sort of thing to do in community
ecological analysis. First of all, let's grab some mammal community
data (again using \texttt{suppdata}):

<<>>=
# Download the community data and then neaten it up a bit
data <- read.csv(esa.archives("E092-201", "MCDB_communities.csv", FALSE))
data$Abundance <- as.numeric(as.character(data$Abundance))
data <- data[!is.na(data$Abundance) & data$Abundance > 0, ]

# Grab the species' names for the community data
species <- read.csv(esa.archives("E092-201", "MCDB_species.csv", FALSE))
data$species <- paste(species$Genus, species$Species)[match(data$Species_ID, species$Species_ID)]
data$species <- gsub("  ", " ", data$species)

# Make a neat community matrix of this data
comm <- as.matrix(sample2matrix(data.frame(data$Site_ID, as.numeric(as.character(data$Abundance)), data$species)))
@ 

Now let's put that all together into a single \R object in
\texttt{pez}, and calculate some summary statistics:

<<>>=
library(pez)
c.data <- comparative.comm(tree, comm, mammal.data)
pez.shape(c.data, traits=TRUE)
@

Done! You could also calculate things in \texttt{vegan} or... whatever
else you want!

\section{Contributing data and/or code to \natdb}
\subsection{Contributing data}
Have you just published some data? Or know of some published data that
others should be using? Great! To get that data into \natdb, you need
to do three things: write a function that loads that data, get the
citation information for that data, and make a pull request (or send
an email) with all of the above.
\subsubsection{Write a function that loads that data}
<<>>=
# Give the function the right name
.pearse.2014 <- function(...){
    # Load the data using suppdata
    data <- read.csv(suppdata("10.6084/m9.figshare.979288", 4), sep = ",", na.strings = c("","NA"))
    
    # Get the data into the right format
    species <- rep(c("Carcinus_maenas"), nrow(data))
    data <- data.frame(species, data)
    metadata <- data[,c(2:3,8:15)]
    data <- data[,-c(2:3,8:15)]
    units <- c(NA, "mm","#","#")
    
    # Return the output from .df.melt
    return(.df.melt(data, "species", units=units, metadata=metadata))
}
@ 

This is the hardest part (sorry!) and it has four parts. The first is
giving the function that will download the data the correct name: a
\texttt{.}, then the first author's surname (\texttt{-} should be
written as a \texttt{_}), a \texttt{.}, and then the year of
publication. If that function name is already taken, either because
there are multiple datasets to be loaded or multiple publications by
that author that year, then add \texttt{a}, \texttt{b}, \texttt{c},
etc., after the function name (\emph{e.g.}, \texttt{.pearse.2014a}).

The second part is loading the data. Please, please, please use
\texttt{suppdata} from \texttt{suppdata}---all it requires is the DOI
of the journal where the paper was published, and either the name of
the supplement or its number where the data is published, to download
that data. I maintain that function in \texttt{suppdata}, so if it's
not possible to download data from the journal you prefer \emph{send
  me an email (\url{will.pearse@usu.edu}) or make an issue on the
  \natdb GitHub (see below) and I will fix this for you}.

The third part is getting the data into the right format. You need to
make a \texttt{data.frame} that contains all the data (the traits), a
column with species names, and nothing else. You should also make a
separate \texttt{data.frame} that contains the meta-data for your
dataset (and nothing else), with a column for each separate piece of
meta-data. Finally, you should make a vector that contains the units
(in standard scientific notation) for the traits you've found. Use
\texttt{NA} for categorical data, \texttt{"?"} when you don't know,
and \texttt{"#"} for count data. For our purposes, meta-data has no
units.

Finally, put it all together! Return the output from \natdb's internal
\texttt{.df.melt} function. You \emph{must} give it some trait data
(the first argument), the column in your trait \texttt{data.frame}
that contains the species' names, and (optionally) the units of your
trait data and the meta-data \texttt{data.frame}. That's it!

If you need more help, please just reach out to me on GitHub or over
email. There are lots more examples of functions in the
\texttt{R/downloads.R} file on the GitHub, if you want to look at more
things.

\subsubsection{Getting the citation information}
Get the citation information for the data you've found ready to give
to me in BibTeX format. I realise BibTeX format might not be familiar
to you (it's also sometimes called \LaTeX format), but it's available
as an `export' option on Google Scholar. If you know what a citation
key is, please make it the first author's surname and then the year of
publication (if you don't know what this means, don't worry about it).

\subsubsection{Make a pull request or email Will}
I think GitHub is amazing, and it's where we keep the \natdb code. If
you're not familiar with Git(Hub), you can learn more here:
\url{https://try.github.io/}. If you know how to, add your function
\emph{in the correct position alphabetically} within the file
\texttt{R/downloads.R}, then make a pull request to the main branch of
\natdb (\url{http://github.com/willpearse/natdb}). Once you've made
that pull request, leave the citation information for your dataset in
the comments section of the pull request.

If that all sounds like nonsense to you, then don't worry! You can
also email me (\url{will.pearse@usu.edu}) with your function in the
body of your email (\emph{not} as an attachment) and with the citation
information in the email as well. If you know how to use GitHub, I'd
prefer to have your function up there because it makes things more
transparent, but email is fine too!

Thank you for contributing to \natdb!

\subsection{Contributing code}
Alright, you got me: technically, everything I've just written above
involves contributing code to \natdb. But perhaps you think the
cleaning code, or the downloading code, could in some way be
streamlined. Perhaps you're looking for something to do, and you'd
like \natdb to be it.

If you've got an idea for how to make the code better, make and issue
about it on GitHub and we can talk about it there. The reason I'd
prefer for you to make an issue \emph{before} writing code is it gives
me a chance to give you feedback. I'd hate for you to start writing
something that we've already started working on, or considered and
decided not to go with, and so end up wasting your time.

If you're looking for something to do, take a look at the issues
because it's likely that there's something that already needs doing up
there. If so, make a pull request with the changes to the main branch
and we're in business! And finally, if you're looking for something to
do but can't find something, then drop me an email
\texttt{will.pearse@usu.edu}. I can assure you I will be able to think
of something for you to do :D

\end{document}
